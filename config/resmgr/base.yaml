storage:
  cassandra:
    # FIXME: need to increase batch size limit dynamically in cassandra (T968823)
    max_batch_size_rows: 1
    max_parallel_batches: 1000
    max_updates_job: 10
    connection:
      contactPoints: ["127.0.0.1"]
      port: 9042
      consistency: LOCAL_QUORUM
      hostPolicy: TokenAwareHostPolicy
      # Need to increase timeout from 10s to 20s to avoid recovery code from timing out
      # We saw recovery code timing out when peloton was recovering from a
      # Cassandra latency spike issue.
      timeout: 20s
    store_name: peloton_test
    migrations: pkg/storage/cassandra/migrations/
  use_cassandra: true

resmgr:
  http_port: 5290
  grpc_port: 5394
  task_scheduling_period: 100ms
  entitlement_calculation_period: 60s
  task_reconciliation_period: 1h
  task:
    placing_timeout: 10m
    launching_timeout: 20m
    # This is the backoff period how much it will backoff
    # in each cycle.
    placement_retry_backoff: 5m
    # This is the cycle which is going to repeat
    # after these many attempts.
    placement_retry_cycle: 3
    # This is the policy name for the backoff
    # which is going to dictate the backoff
    backoff_policy_name: exponential-policy
    # This flag enable/disable the placement backoff
    enable_placement_backoff: true
  preemption:
    task_preemption_period: 60s
    sustained_over_allocation_count: 5
    enabled: true
  host_drainer_period: 300s
  recovery:
    recover_from_active_jobs: false

election:
  root: "/peloton"

health:
  heartbeat_interval: 5s

metrics:
  runtime_metrics:
    enabled: true
    interval: 10s
